{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll be using [Kaggle](https://www.kaggle.com/ashishbansal23/emotion-recognition/data) dataset to train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's break down the codes and understand it\n",
    "- Sequential library basically means that we are going to create linear stack of layers where the output of neurons of one layer will serve as the input to the next layer and in this way we'll get something like tree with roots coming out and getting more complex, more info keras.\n",
    "- Conv2D basically tries to fetch the important information from the image like curve, smoothness, or a particular patterns\n",
    "- MaxPooling2D work is to reduce the size of the matrix without compromising with the information that it contains\n",
    "- Flatten work is to convert the madrix to the one dimensional vector so that its each element could then be used as an input to the artificial neural network\n",
    "- Dense is used to add more layer to the ann efficiently i suppose\n",
    "- Batch Normalization, actually normalize the activation so that it is close to zero and the activation deviation is close to 1, more on [keras](https://keras.io/layers/normalization/)\n",
    "- np_utils will help us in reformatting the dataset obtained from the kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there is an interseting thing about this dataset, you won't be able to open it with the help of excel or google sheets, this is because the formatting of the dataset, I recommend using Spyder, to read this file\n",
    "- the dataset has 3 columns emotion, pixels and Usage, we need to first extract the data whose Usage is for Training purposes and we'll then use it to train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"spyder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"]==\"Training\"]\n",
    "train_dataset['pixels'] = train_dataset['pixels'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "X_train = np.vstack(train_dataset['pixels'].values)\n",
    "y_train = np.vstack(train_dataset['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first we are extracting the data correspoding to the Usage 'Training'\n",
    "- because the data in the Pixels column is in string we need to convert it into array, because our model won't recognise input data as string\n",
    "- np.vstack is basically used to combine all the information into array\n",
    "- in y_train we want the labels whether the information is of happy,sad,angry etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"]==\"PublicTest\"]\n",
    "test_dataset['pixels'] = test_dataset['pixels'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "X_test = np.vstack(test_dataset['pixels'].values)\n",
    "y_test = np.vstack(test_dataset['emotion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 48, 48, 1)\n",
    "X_test = X_test.reshape(-1, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we are reshaping the matrix because the our model wants a matrix having dimension (-1, 48, 48, 1)\n",
    "- we have 2034 pixel data in one row in pixel columns so it can be reshaped into 48 * 48 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as there are 7 categories in the column emotion and each category is represented by the number 1 to 7, but as we know these are labels so we need to create dummy variables to make our model don't interpret these labels as numbers like, 7 < 6, because these are not numbers, they are labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' applying the convolution\n",
    " actually we are providing the pixels to the model that was given\n",
    " so we don't need to convert the image to pixel\n",
    " but if we want to test the image then we have \n",
    "to manually convert it into the 48 * 48 size further it should be greyscale\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(64, (5, 5), input_shape=(48,48,1), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 44, 44, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 18, 18, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 32)          18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 150,023\n",
      "Trainable params: 149,639\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='highly_trained_model.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train,\n",
    "                      epochs=epochs,\n",
    "                      shuffle=True,\n",
    "                      batch_size=32,\n",
    "                      validation_data=(X_test,y_test),\n",
    "                      callbacks=[checkpointer],\n",
    "                      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model on a Different Dataset provided in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "test_f = dataset[[\"emotion\", \"pixels\"]][dataset[\"Usage\"] == \"PrivateTest\"]\n",
    "test_f[\"pixels\"] = test_f[\"pixels\"].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "x_test_private = np.vstack(test[\"pixels\"].values)\n",
    "y_test_private = np.array(test[\"emotion\"])\n",
    "\n",
    "x_test_private = x_test_private.reshape(-1, 48, 48, 1)\n",
    "y_test_private = np_utils.to_categorical(y_test_private)\n",
    "\n",
    "score = classifier.evaluate(x_test_private, y_test_private, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
